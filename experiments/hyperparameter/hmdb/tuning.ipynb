{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6696d1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c5a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from mmaction.datasets import build_dataset, build_dataloader\n",
    "from mmaction.models import build_model\n",
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3cec5",
   "metadata": {},
   "source": [
    "## Loading batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9df620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('./baseline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0258630",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2c341f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'RawframeDataset',\n",
       " 'ann_file': 'data/hmdb51/annotation_train.txt',\n",
       " 'data_prefix': 'data/hmdb51/rawframes',\n",
       " 'pipeline': [{'type': 'SampleFrames',\n",
       "   'clip_len': 32,\n",
       "   'frame_interval': 2,\n",
       "   'num_clips': 1},\n",
       "  {'type': 'RawFrameDecode'},\n",
       "  {'type': 'Resize', 'scale': (-1, 256)},\n",
       "  {'type': 'RandomResizedCrop'},\n",
       "  {'type': 'Resize', 'scale': (224, 224), 'keep_ratio': False},\n",
       "  {'type': 'Flip', 'flip_ratio': 0.5},\n",
       "  {'type': 'Normalize',\n",
       "   'mean': [123.675, 116.28, 103.53],\n",
       "   'std': [58.395, 57.12, 57.375],\n",
       "   'to_bgr': False},\n",
       "  {'type': 'FormatShape', 'input_format': 'NCTHW'},\n",
       "  {'type': 'Collect', 'keys': ['imgs', 'label'], 'meta_keys': []},\n",
       "  {'type': 'ToTensor', 'keys': ['imgs', 'label']}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccef55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(cfg=cfg.data.train)\n",
    "train_loader = build_dataloader(\n",
    "        train_dataset,\n",
    "        videos_per_gpu=10,\n",
    "        workers_per_gpu=4,\n",
    "        persistent_workers=False,\n",
    "        num_gpus=1,\n",
    "        dist=False)\n",
    "\n",
    "val_dataset = build_dataset(cfg=cfg.data.val)\n",
    "val_loader = build_dataloader(\n",
    "        val_dataset,\n",
    "        videos_per_gpu=1,\n",
    "        workers_per_gpu=4,\n",
    "        persistent_workers=False,\n",
    "        num_gpus=1,\n",
    "        dist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eacfdb",
   "metadata": {},
   "source": [
    "## Learning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b5656d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-05 07:47:03,482] Using an existing study with name 'my_study' instead of creating a new one.\n",
      "/tmp/ipykernel_3909566/2058400291.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
      "2024-11-05 07:47:03,924 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 07:47:03,925 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 07:47:03,959 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for layer1.0.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer1.1.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer1.2.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer2.0.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.1.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.2.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.3.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer3.0.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.1.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.2.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.3.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.4.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.5.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer4.0.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "size mismatch for layer4.1.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "size mismatch for layer4.2.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "missing keys in source state_dict: layer1.0.conv2.1.conv.weight, layer1.0.conv2.1.bn.weight, layer1.0.conv2.1.bn.bias, layer1.0.conv2.1.bn.running_mean, layer1.0.conv2.1.bn.running_var, layer1.1.conv2.1.conv.weight, layer1.1.conv2.1.bn.weight, layer1.1.conv2.1.bn.bias, layer1.1.conv2.1.bn.running_mean, layer1.1.conv2.1.bn.running_var, layer1.2.conv2.1.conv.weight, layer1.2.conv2.1.bn.weight, layer1.2.conv2.1.bn.bias, layer1.2.conv2.1.bn.running_mean, layer1.2.conv2.1.bn.running_var, layer2.0.conv2.1.conv.weight, layer2.0.conv2.1.bn.weight, layer2.0.conv2.1.bn.bias, layer2.0.conv2.1.bn.running_mean, layer2.0.conv2.1.bn.running_var, layer2.1.conv2.1.conv.weight, layer2.1.conv2.1.bn.weight, layer2.1.conv2.1.bn.bias, layer2.1.conv2.1.bn.running_mean, layer2.1.conv2.1.bn.running_var, layer2.2.conv2.1.conv.weight, layer2.2.conv2.1.bn.weight, layer2.2.conv2.1.bn.bias, layer2.2.conv2.1.bn.running_mean, layer2.2.conv2.1.bn.running_var, layer2.3.conv2.1.conv.weight, layer2.3.conv2.1.bn.weight, layer2.3.conv2.1.bn.bias, layer2.3.conv2.1.bn.running_mean, layer2.3.conv2.1.bn.running_var, layer3.0.conv2.1.conv.weight, layer3.0.conv2.1.bn.weight, layer3.0.conv2.1.bn.bias, layer3.0.conv2.1.bn.running_mean, layer3.0.conv2.1.bn.running_var, layer3.1.conv2.1.conv.weight, layer3.1.conv2.1.bn.weight, layer3.1.conv2.1.bn.bias, layer3.1.conv2.1.bn.running_mean, layer3.1.conv2.1.bn.running_var, layer3.2.conv2.1.conv.weight, layer3.2.conv2.1.bn.weight, layer3.2.conv2.1.bn.bias, layer3.2.conv2.1.bn.running_mean, layer3.2.conv2.1.bn.running_var, layer3.3.conv2.1.conv.weight, layer3.3.conv2.1.bn.weight, layer3.3.conv2.1.bn.bias, layer3.3.conv2.1.bn.running_mean, layer3.3.conv2.1.bn.running_var, layer3.4.conv2.1.conv.weight, layer3.4.conv2.1.bn.weight, layer3.4.conv2.1.bn.bias, layer3.4.conv2.1.bn.running_mean, layer3.4.conv2.1.bn.running_var, layer3.5.conv2.1.conv.weight, layer3.5.conv2.1.bn.weight, layer3.5.conv2.1.bn.bias, layer3.5.conv2.1.bn.running_mean, layer3.5.conv2.1.bn.running_var, layer4.0.conv2.1.conv.weight, layer4.0.conv2.1.bn.weight, layer4.0.conv2.1.bn.bias, layer4.0.conv2.1.bn.running_mean, layer4.0.conv2.1.bn.running_var, layer4.1.conv2.1.conv.weight, layer4.1.conv2.1.bn.weight, layer4.1.conv2.1.bn.bias, layer4.1.conv2.1.bn.running_mean, layer4.1.conv2.1.bn.running_var, layer4.2.conv2.1.conv.weight, layer4.2.conv2.1.bn.weight, layer4.2.conv2.1.bn.bias, layer4.2.conv2.1.bn.running_mean, layer4.2.conv2.1.bn.running_var\n",
      "\n",
      "[I 2024-11-05 08:59:10,221] Trial 6 finished with value: 0.0196078431372549 and parameters: {'dropout_ratio': 0.4324902501275922, 'lr': 0.0006949883518180806, 'warmup_ratio': 0.16613267933841713, 'max_norm': 23, 'with_pool2': True, 'bottleneck_mode': 'ip', 'norm_eval': True, 'bn_frozen': False}. Best is trial 0 with value: 0.7588235294117647.\n",
      "2024-11-05 08:59:10,602 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 08:59:10,603 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 08:59:10,632 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for layer1.0.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer1.1.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer1.2.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer2.0.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.1.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.2.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.3.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer3.0.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.1.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.2.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.3.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.4.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.5.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer4.0.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "size mismatch for layer4.1.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "size mismatch for layer4.2.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "missing keys in source state_dict: layer1.0.conv2.1.conv.weight, layer1.0.conv2.1.bn.weight, layer1.0.conv2.1.bn.bias, layer1.0.conv2.1.bn.running_mean, layer1.0.conv2.1.bn.running_var, layer1.1.conv2.1.conv.weight, layer1.1.conv2.1.bn.weight, layer1.1.conv2.1.bn.bias, layer1.1.conv2.1.bn.running_mean, layer1.1.conv2.1.bn.running_var, layer1.2.conv2.1.conv.weight, layer1.2.conv2.1.bn.weight, layer1.2.conv2.1.bn.bias, layer1.2.conv2.1.bn.running_mean, layer1.2.conv2.1.bn.running_var, layer2.0.conv2.1.conv.weight, layer2.0.conv2.1.bn.weight, layer2.0.conv2.1.bn.bias, layer2.0.conv2.1.bn.running_mean, layer2.0.conv2.1.bn.running_var, layer2.1.conv2.1.conv.weight, layer2.1.conv2.1.bn.weight, layer2.1.conv2.1.bn.bias, layer2.1.conv2.1.bn.running_mean, layer2.1.conv2.1.bn.running_var, layer2.2.conv2.1.conv.weight, layer2.2.conv2.1.bn.weight, layer2.2.conv2.1.bn.bias, layer2.2.conv2.1.bn.running_mean, layer2.2.conv2.1.bn.running_var, layer2.3.conv2.1.conv.weight, layer2.3.conv2.1.bn.weight, layer2.3.conv2.1.bn.bias, layer2.3.conv2.1.bn.running_mean, layer2.3.conv2.1.bn.running_var, layer3.0.conv2.1.conv.weight, layer3.0.conv2.1.bn.weight, layer3.0.conv2.1.bn.bias, layer3.0.conv2.1.bn.running_mean, layer3.0.conv2.1.bn.running_var, layer3.1.conv2.1.conv.weight, layer3.1.conv2.1.bn.weight, layer3.1.conv2.1.bn.bias, layer3.1.conv2.1.bn.running_mean, layer3.1.conv2.1.bn.running_var, layer3.2.conv2.1.conv.weight, layer3.2.conv2.1.bn.weight, layer3.2.conv2.1.bn.bias, layer3.2.conv2.1.bn.running_mean, layer3.2.conv2.1.bn.running_var, layer3.3.conv2.1.conv.weight, layer3.3.conv2.1.bn.weight, layer3.3.conv2.1.bn.bias, layer3.3.conv2.1.bn.running_mean, layer3.3.conv2.1.bn.running_var, layer3.4.conv2.1.conv.weight, layer3.4.conv2.1.bn.weight, layer3.4.conv2.1.bn.bias, layer3.4.conv2.1.bn.running_mean, layer3.4.conv2.1.bn.running_var, layer3.5.conv2.1.conv.weight, layer3.5.conv2.1.bn.weight, layer3.5.conv2.1.bn.bias, layer3.5.conv2.1.bn.running_mean, layer3.5.conv2.1.bn.running_var, layer4.0.conv2.1.conv.weight, layer4.0.conv2.1.bn.weight, layer4.0.conv2.1.bn.bias, layer4.0.conv2.1.bn.running_mean, layer4.0.conv2.1.bn.running_var, layer4.1.conv2.1.conv.weight, layer4.1.conv2.1.bn.weight, layer4.1.conv2.1.bn.bias, layer4.1.conv2.1.bn.running_mean, layer4.1.conv2.1.bn.running_var, layer4.2.conv2.1.conv.weight, layer4.2.conv2.1.bn.weight, layer4.2.conv2.1.bn.bias, layer4.2.conv2.1.bn.running_mean, layer4.2.conv2.1.bn.running_var\n",
      "\n",
      "[I 2024-11-05 09:09:46,031] Trial 7 pruned. \n",
      "2024-11-05 09:09:46,427 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 09:09:46,428 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 09:09:46,459 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for layer1.0.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer1.1.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer1.2.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer2.0.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.1.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.2.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.3.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer3.0.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.1.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.2.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.3.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.4.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.5.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer4.0.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "size mismatch for layer4.1.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "size mismatch for layer4.2.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "missing keys in source state_dict: layer1.0.conv2.1.conv.weight, layer1.0.conv2.1.bn.weight, layer1.0.conv2.1.bn.bias, layer1.0.conv2.1.bn.running_mean, layer1.0.conv2.1.bn.running_var, layer1.1.conv2.1.conv.weight, layer1.1.conv2.1.bn.weight, layer1.1.conv2.1.bn.bias, layer1.1.conv2.1.bn.running_mean, layer1.1.conv2.1.bn.running_var, layer1.2.conv2.1.conv.weight, layer1.2.conv2.1.bn.weight, layer1.2.conv2.1.bn.bias, layer1.2.conv2.1.bn.running_mean, layer1.2.conv2.1.bn.running_var, layer2.0.conv2.1.conv.weight, layer2.0.conv2.1.bn.weight, layer2.0.conv2.1.bn.bias, layer2.0.conv2.1.bn.running_mean, layer2.0.conv2.1.bn.running_var, layer2.1.conv2.1.conv.weight, layer2.1.conv2.1.bn.weight, layer2.1.conv2.1.bn.bias, layer2.1.conv2.1.bn.running_mean, layer2.1.conv2.1.bn.running_var, layer2.2.conv2.1.conv.weight, layer2.2.conv2.1.bn.weight, layer2.2.conv2.1.bn.bias, layer2.2.conv2.1.bn.running_mean, layer2.2.conv2.1.bn.running_var, layer2.3.conv2.1.conv.weight, layer2.3.conv2.1.bn.weight, layer2.3.conv2.1.bn.bias, layer2.3.conv2.1.bn.running_mean, layer2.3.conv2.1.bn.running_var, layer3.0.conv2.1.conv.weight, layer3.0.conv2.1.bn.weight, layer3.0.conv2.1.bn.bias, layer3.0.conv2.1.bn.running_mean, layer3.0.conv2.1.bn.running_var, layer3.1.conv2.1.conv.weight, layer3.1.conv2.1.bn.weight, layer3.1.conv2.1.bn.bias, layer3.1.conv2.1.bn.running_mean, layer3.1.conv2.1.bn.running_var, layer3.2.conv2.1.conv.weight, layer3.2.conv2.1.bn.weight, layer3.2.conv2.1.bn.bias, layer3.2.conv2.1.bn.running_mean, layer3.2.conv2.1.bn.running_var, layer3.3.conv2.1.conv.weight, layer3.3.conv2.1.bn.weight, layer3.3.conv2.1.bn.bias, layer3.3.conv2.1.bn.running_mean, layer3.3.conv2.1.bn.running_var, layer3.4.conv2.1.conv.weight, layer3.4.conv2.1.bn.weight, layer3.4.conv2.1.bn.bias, layer3.4.conv2.1.bn.running_mean, layer3.4.conv2.1.bn.running_var, layer3.5.conv2.1.conv.weight, layer3.5.conv2.1.bn.weight, layer3.5.conv2.1.bn.bias, layer3.5.conv2.1.bn.running_mean, layer3.5.conv2.1.bn.running_var, layer4.0.conv2.1.conv.weight, layer4.0.conv2.1.bn.weight, layer4.0.conv2.1.bn.bias, layer4.0.conv2.1.bn.running_mean, layer4.0.conv2.1.bn.running_var, layer4.1.conv2.1.conv.weight, layer4.1.conv2.1.bn.weight, layer4.1.conv2.1.bn.bias, layer4.1.conv2.1.bn.running_mean, layer4.1.conv2.1.bn.running_var, layer4.2.conv2.1.conv.weight, layer4.2.conv2.1.bn.weight, layer4.2.conv2.1.bn.bias, layer4.2.conv2.1.bn.running_mean, layer4.2.conv2.1.bn.running_var\n",
      "\n",
      "[I 2024-11-05 09:20:00,617] Trial 8 pruned. \n",
      "2024-11-05 09:20:00,990 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 09:20:00,991 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 09:30:38,019] Trial 9 pruned. \n",
      "2024-11-05 09:30:38,402 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 09:30:38,402 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 09:41:43,625] Trial 10 pruned. \n",
      "2024-11-05 09:41:44,015 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 09:41:44,016 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 09:41:44,046 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for layer1.0.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer1.1.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer1.2.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
      "size mismatch for layer2.0.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.1.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.2.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer2.3.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
      "size mismatch for layer3.0.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.1.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.2.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.3.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.4.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer3.5.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
      "size mismatch for layer4.0.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "size mismatch for layer4.1.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "size mismatch for layer4.2.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
      "missing keys in source state_dict: layer1.0.conv2.1.conv.weight, layer1.0.conv2.1.bn.weight, layer1.0.conv2.1.bn.bias, layer1.0.conv2.1.bn.running_mean, layer1.0.conv2.1.bn.running_var, layer1.1.conv2.1.conv.weight, layer1.1.conv2.1.bn.weight, layer1.1.conv2.1.bn.bias, layer1.1.conv2.1.bn.running_mean, layer1.1.conv2.1.bn.running_var, layer1.2.conv2.1.conv.weight, layer1.2.conv2.1.bn.weight, layer1.2.conv2.1.bn.bias, layer1.2.conv2.1.bn.running_mean, layer1.2.conv2.1.bn.running_var, layer2.0.conv2.1.conv.weight, layer2.0.conv2.1.bn.weight, layer2.0.conv2.1.bn.bias, layer2.0.conv2.1.bn.running_mean, layer2.0.conv2.1.bn.running_var, layer2.1.conv2.1.conv.weight, layer2.1.conv2.1.bn.weight, layer2.1.conv2.1.bn.bias, layer2.1.conv2.1.bn.running_mean, layer2.1.conv2.1.bn.running_var, layer2.2.conv2.1.conv.weight, layer2.2.conv2.1.bn.weight, layer2.2.conv2.1.bn.bias, layer2.2.conv2.1.bn.running_mean, layer2.2.conv2.1.bn.running_var, layer2.3.conv2.1.conv.weight, layer2.3.conv2.1.bn.weight, layer2.3.conv2.1.bn.bias, layer2.3.conv2.1.bn.running_mean, layer2.3.conv2.1.bn.running_var, layer3.0.conv2.1.conv.weight, layer3.0.conv2.1.bn.weight, layer3.0.conv2.1.bn.bias, layer3.0.conv2.1.bn.running_mean, layer3.0.conv2.1.bn.running_var, layer3.1.conv2.1.conv.weight, layer3.1.conv2.1.bn.weight, layer3.1.conv2.1.bn.bias, layer3.1.conv2.1.bn.running_mean, layer3.1.conv2.1.bn.running_var, layer3.2.conv2.1.conv.weight, layer3.2.conv2.1.bn.weight, layer3.2.conv2.1.bn.bias, layer3.2.conv2.1.bn.running_mean, layer3.2.conv2.1.bn.running_var, layer3.3.conv2.1.conv.weight, layer3.3.conv2.1.bn.weight, layer3.3.conv2.1.bn.bias, layer3.3.conv2.1.bn.running_mean, layer3.3.conv2.1.bn.running_var, layer3.4.conv2.1.conv.weight, layer3.4.conv2.1.bn.weight, layer3.4.conv2.1.bn.bias, layer3.4.conv2.1.bn.running_mean, layer3.4.conv2.1.bn.running_var, layer3.5.conv2.1.conv.weight, layer3.5.conv2.1.bn.weight, layer3.5.conv2.1.bn.bias, layer3.5.conv2.1.bn.running_mean, layer3.5.conv2.1.bn.running_var, layer4.0.conv2.1.conv.weight, layer4.0.conv2.1.bn.weight, layer4.0.conv2.1.bn.bias, layer4.0.conv2.1.bn.running_mean, layer4.0.conv2.1.bn.running_var, layer4.1.conv2.1.conv.weight, layer4.1.conv2.1.bn.weight, layer4.1.conv2.1.bn.bias, layer4.1.conv2.1.bn.running_mean, layer4.1.conv2.1.bn.running_var, layer4.2.conv2.1.conv.weight, layer4.2.conv2.1.bn.weight, layer4.2.conv2.1.bn.bias, layer4.2.conv2.1.bn.running_mean, layer4.2.conv2.1.bn.running_var\n",
      "\n",
      "[I 2024-11-05 09:52:20,316] Trial 11 pruned. \n",
      "2024-11-05 09:52:20,697 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 09:52:20,698 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 10:03:26,308] Trial 12 pruned. \n",
      "2024-11-05 10:03:26,701 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 10:03:26,702 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 10:14:32,107] Trial 13 pruned. \n",
      "2024-11-05 10:14:32,492 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 10:14:32,493 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 10:25:38,096] Trial 14 pruned. \n",
      "2024-11-05 10:25:38,485 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 10:25:38,486 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 11:43:12,756] Trial 15 finished with value: 0.7496732026143791 and parameters: {'dropout_ratio': 0.685574714752577, 'lr': 0.0003431560558990482, 'warmup_ratio': 0.16037710560434615, 'max_norm': 34, 'with_pool2': False, 'bottleneck_mode': 'ir', 'norm_eval': False, 'bn_frozen': True}. Best is trial 0 with value: 0.7588235294117647.\n",
      "2024-11-05 11:43:13,133 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 11:43:13,134 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 11:54:18,012] Trial 16 pruned. \n",
      "2024-11-05 11:54:18,407 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 11:54:18,408 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 12:05:24,073] Trial 17 pruned. \n",
      "2024-11-05 12:05:24,459 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 12:05:24,460 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 13:23:38,027] Trial 18 finished with value: 0.745751633986928 and parameters: {'dropout_ratio': 0.5262546432228076, 'lr': 0.00041551333724021764, 'warmup_ratio': 0.1584034812959933, 'max_norm': 50, 'with_pool2': False, 'bottleneck_mode': 'ir', 'norm_eval': False, 'bn_frozen': True}. Best is trial 0 with value: 0.7588235294117647.\n",
      "2024-11-05 13:23:38,410 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 13:23:38,411 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 13:36:05,903] Trial 19 pruned. \n",
      "2024-11-05 13:36:06,300 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 13:36:06,301 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 14:50:34,807] Trial 20 finished with value: 0.7712418300653594 and parameters: {'dropout_ratio': 0.526359895507142, 'lr': 0.00041991630239679586, 'warmup_ratio': 0.19984035642104114, 'max_norm': 10, 'with_pool2': False, 'bottleneck_mode': 'ir', 'norm_eval': True, 'bn_frozen': False}. Best is trial 20 with value: 0.7712418300653594.\n",
      "2024-11-05 14:50:35,277 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 14:50:35,278 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 15:01:13,853] Trial 21 pruned. \n",
      "2024-11-05 15:01:14,255 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 15:01:14,256 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 15:11:53,011] Trial 22 pruned. \n",
      "2024-11-05 15:11:53,399 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 15:11:53,400 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[I 2024-11-05 15:33:09,828] Trial 23 pruned. \n",
      "2024-11-05 15:33:10,220 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-05 15:33:10,221 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "[W 2024-11-05 15:56:00,926] Trial 24 failed with parameters: {'dropout_ratio': 0.4536040897448642, 'lr': 0.0009720843058238105, 'warmup_ratio': 0.1594576529425153, 'max_norm': 27, 'with_pool2': False, 'bottleneck_mode': 'ir', 'norm_eval': True, 'bn_frozen': False} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3909566/2058400291.py\", line 83, in objective\n",
      "    results = model(inputs, labels, return_loss=True)\n",
      "  File \"/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmaction/models/recognizers/base.py\", line 269, in forward\n",
      "    return self.forward_train(imgs, label, **kwargs)\n",
      "  File \"/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmaction/models/recognizers/recognizer3d.py\", line 27, in forward_train\n",
      "    loss_cls = self.cls_head.loss(cls_score, gt_labels, **kwargs)\n",
      "  File \"/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmaction/models/heads/base.py\", line 99, in loss\n",
      "    top_k_acc = top_k_accuracy(cls_score.detach().cpu().numpy(),\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-05 15:56:00,928] Trial 24 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_accuracy \n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Run Optuna Study\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m    130\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest validation accuracy: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_value)\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[6], line 83\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     80\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimgs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     82\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 83\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m loss \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_cls\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     85\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmaction/models/recognizers/base.py:269\u001b[0m, in \u001b[0;36mBaseRecognizer.forward\u001b[0;34m(self, imgs, label, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         imgs, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblending(imgs, label)\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_test(imgs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmaction/models/recognizers/recognizer3d.py:27\u001b[0m, in \u001b[0;36mRecognizer3D.forward_train\u001b[0;34m(self, imgs, labels, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m cls_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_head(x)\n\u001b[1;32m     26\u001b[0m gt_labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 27\u001b[0m loss_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(loss_cls)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmaction/models/heads/base.py:99\u001b[0m, in \u001b[0;36mBaseHead.loss\u001b[0;34m(self, cls_score, labels, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01mand\u001b[39;00m cls_score\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m---> 99\u001b[0m     top_k_acc \u001b[38;5;241m=\u001b[39m top_k_accuracy(\u001b[43mcls_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    100\u001b[0m                                labels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    101\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopk)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopk, top_k_acc):\n\u001b[1;32m    103\u001b[0m         losses[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_acc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    104\u001b[0m             a, device\u001b[38;5;241m=\u001b[39mcls_score\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from mmcv import Config\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='optuna_training.log', \n",
    "                    filemode='w', \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    level=logging.INFO)\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Database file path for saving study\n",
    "db_file = \"sqlite:///optuna_study.db\"\n",
    "\n",
    "# Set up study with the option to resume if it already exists\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\", \n",
    "    study_name=\"my_study\", \n",
    "    storage=db_file,\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    dropout_ratio = trial.suggest_float(\"dropout_ratio\", 0.3, 0.7)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.05, 0.2)\n",
    "    max_norm = trial.suggest_int(\"max_norm\", 10, 50)\n",
    "    \n",
    "    # Backbone parameters\n",
    "    cfg.model.backbone.with_pool2 = trial.suggest_categorical(\"with_pool2\", [True, False])\n",
    "    cfg.model.backbone.bottleneck_mode = trial.suggest_categorical(\"bottleneck_mode\", [\"ir\", \"ip\"])\n",
    "    cfg.model.backbone.norm_eval = trial.suggest_categorical(\"norm_eval\", [True, False])\n",
    "    cfg.model.backbone.bn_frozen = trial.suggest_categorical(\"bn_frozen\", [True, False])\n",
    "    \n",
    "    # Fixed pretrained URL\n",
    "    cfg.model.backbone.pretrained = 'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth'\n",
    "\n",
    "    # Adjust config parameters\n",
    "    cfg.model.cls_head.dropout_ratio = dropout_ratio\n",
    "    warmup_start_lr = lr * warmup_ratio\n",
    "    initial_lr = lr\n",
    "    \n",
    "    # Initialize model, criterion, optimizer, scheduler\n",
    "    model = build_model(cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg')).to(device)\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=initial_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001\n",
    "    )\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[70, 140], gamma=0.1)\n",
    "    \n",
    "    # Warmup settings\n",
    "    warmup_epochs = 16\n",
    "\n",
    "    # Training and validation\n",
    "    total_epochs = 35\n",
    "    eval_interval = 5\n",
    "    \n",
    "    for epoch in range(total_epochs):\n",
    "        if epoch < warmup_epochs:\n",
    "            warmup_lr = warmup_start_lr + (initial_lr - warmup_start_lr) * (epoch / warmup_epochs)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = warmup_lr\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data['imgs'].to(device), data['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            results = model(inputs, labels, return_loss=True)\n",
    "            loss = results['loss_cls']\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            correct += (results['top1_acc'] * inputs.size(0))\n",
    "            total += inputs.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        logging.info(f\"Epoch [{epoch + 1}/{total_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Validation loop (every `eval_interval` epochs)\n",
    "        if (epoch + 1) % eval_interval == 0:\n",
    "            model.eval()\n",
    "            val_running_loss, val_correct, val_total = 0.0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for val_data in val_loader:\n",
    "                    val_inputs, val_labels = val_data['imgs'].to(device), val_data['label'].to(device)\n",
    "                    \n",
    "                    val_results = model(val_inputs, val_labels, return_loss=True)\n",
    "                    val_loss = val_results['loss_cls']\n",
    "                    val_running_loss += val_loss.item()\n",
    "                    val_correct += (val_results['top1_acc'] * val_inputs.size(0))\n",
    "                    val_total += val_inputs.size(0)\n",
    "\n",
    "            val_accuracy = val_correct / val_total\n",
    "            val_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "            # Report validation accuracy to Optuna\n",
    "            trial.report(val_accuracy, epoch)\n",
    "\n",
    "            # Prune unpromising trials\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return val_accuracy \n",
    "\n",
    "# Run Optuna Study\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "logging.info(\"Best hyperparameters: %s\", study.best_params)\n",
    "logging.info(\"Best validation accuracy: %f\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e65949",
   "metadata": {},
   "source": [
    "[I 2024-11-05 02:02:27,080] Using an existing study with name 'my_study' instead of creating a new one.\n",
    "/tmp/ipykernel_930960/1812890224.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "2024-11-05 02:02:27,513 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
    "2024-11-05 02:02:27,514 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
    "[I 2024-11-05 03:03:39,859] Trial 2 finished with value: 0.6947712418300653 and parameters: {'dropout_ratio': 0.37629465362426134, 'lr': 7.80756602206136e-05, 'warmup_ratio': 0.11381606982740221, 'max_norm': 39, 'with_pool2': True, 'bottleneck_mode': 'ir', 'norm_eval': True, 'bn_frozen': True}. Best is trial 0 with value: 0.7588235294117647.\n",
    "2024-11-05 03:03:40,235 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
    "2024-11-05 03:03:40,236 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
    "2024-11-05 03:03:40,268 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
    "\n",
    "size mismatch for layer1.0.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
    "size mismatch for layer1.1.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
    "size mismatch for layer1.2.conv2.0.conv.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1, 1]).\n",
    "size mismatch for layer2.0.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
    "size mismatch for layer2.1.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
    "size mismatch for layer2.2.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
    "size mismatch for layer2.3.conv2.0.conv.weight: copying a param with shape torch.Size([128, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1, 1]).\n",
    "size mismatch for layer3.0.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
    "size mismatch for layer3.1.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
    "size mismatch for layer3.2.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
    "size mismatch for layer3.3.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
    "size mismatch for layer3.4.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
    "size mismatch for layer3.5.conv2.0.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1, 1]).\n",
    "size mismatch for layer4.0.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
    "size mismatch for layer4.1.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
    "size mismatch for layer4.2.conv2.0.conv.weight: copying a param with shape torch.Size([512, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1, 1]).\n",
    "missing keys in source state_dict: layer1.0.conv2.1.conv.weight, layer1.0.conv2.1.bn.weight, layer1.0.conv2.1.bn.bias, layer1.0.conv2.1.bn.running_mean, layer1.0.conv2.1.bn.running_var, layer1.1.conv2.1.conv.weight, layer1.1.conv2.1.bn.weight, layer1.1.conv2.1.bn.bias, layer1.1.conv2.1.bn.running_mean, layer1.1.conv2.1.bn.running_var, layer1.2.conv2.1.conv.weight, layer1.2.conv2.1.bn.weight, layer1.2.conv2.1.bn.bias, layer1.2.conv2.1.bn.running_mean, layer1.2.conv2.1.bn.running_var, layer2.0.conv2.1.conv.weight, layer2.0.conv2.1.bn.weight, layer2.0.conv2.1.bn.bias, layer2.0.conv2.1.bn.running_mean, layer2.0.conv2.1.bn.running_var, layer2.1.conv2.1.conv.weight, layer2.1.conv2.1.bn.weight, layer2.1.conv2.1.bn.bias, layer2.1.conv2.1.bn.running_mean, layer2.1.conv2.1.bn.running_var, layer2.2.conv2.1.conv.weight, layer2.2.conv2.1.bn.weight, layer2.2.conv2.1.bn.bias, layer2.2.conv2.1.bn.running_mean, layer2.2.conv2.1.bn.running_var, layer2.3.conv2.1.conv.weight, layer2.3.conv2.1.bn.weight, layer2.3.conv2.1.bn.bias, layer2.3.conv2.1.bn.running_mean, layer2.3.conv2.1.bn.running_var, layer3.0.conv2.1.conv.weight, layer3.0.conv2.1.bn.weight, layer3.0.conv2.1.bn.bias, layer3.0.conv2.1.bn.running_mean, layer3.0.conv2.1.bn.running_var, layer3.1.conv2.1.conv.weight, layer3.1.conv2.1.bn.weight, layer3.1.conv2.1.bn.bias, layer3.1.conv2.1.bn.running_mean, layer3.1.conv2.1.bn.running_var, layer3.2.conv2.1.conv.weight, layer3.2.conv2.1.bn.weight, layer3.2.conv2.1.bn.bias, layer3.2.conv2.1.bn.running_mean, layer3.2.conv2.1.bn.running_var, layer3.3.conv2.1.conv.weight, layer3.3.conv2.1.bn.weight, layer3.3.conv2.1.bn.bias, layer3.3.conv2.1.bn.running_mean, layer3.3.conv2.1.bn.running_var, layer3.4.conv2.1.conv.weight, layer3.4.conv2.1.bn.weight, layer3.4.conv2.1.bn.bias, layer3.4.conv2.1.bn.running_mean, layer3.4.conv2.1.bn.running_var, layer3.5.conv2.1.conv.weight, layer3.5.conv2.1.bn.weight, layer3.5.conv2.1.bn.bias, layer3.5.conv2.1.bn.running_mean, layer3.5.conv2.1.bn.running_var, layer4.0.conv2.1.conv.weight, layer4.0.conv2.1.bn.weight, layer4.0.conv2.1.bn.bias, layer4.0.conv2.1.bn.running_mean, layer4.0.conv2.1.bn.running_var, layer4.1.conv2.1.conv.weight, layer4.1.conv2.1.bn.weight, layer4.1.conv2.1.bn.bias, layer4.1.conv2.1.bn.running_mean, layer4.1.conv2.1.bn.running_var, layer4.2.conv2.1.conv.weight, layer4.2.conv2.1.bn.weight, layer4.2.conv2.1.bn.bias, layer4.2.conv2.1.bn.running_mean, layer4.2.conv2.1.bn.running_var\n",
    "\n",
    "[I 2024-11-05 04:17:34,351] Trial 3 finished with value: 0.19607843137254902 and parameters: {'dropout_ratio': 0.6300026158652796, 'lr': 0.0007329990590709254, 'warmup_ratio': 0.07932626660238631, 'max_norm': 23, 'with_pool2': True, 'bottleneck_mode': 'ip', 'norm_eval': False, 'bn_frozen': False}. Best is trial 0 with value: 0.7588235294117647.\n",
    "2024-11-05 04:17:34,722 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
    "2024-11-05 04:17:34,723 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
    "[I 2024-11-05 05:25:47,516] Trial 4 finished with value: 0.7039215686274509 and parameters: {'dropout_ratio': 0.6152719310623556, 'lr': 0.00041679938242399035, 'warmup_ratio': 0.17738656176381717, 'max_norm': 29, 'with_pool2': True, 'bottleneck_mode': 'ir', 'norm_eval': False, 'bn_frozen': True}. Best is trial 0 with value: 0.7588235294117647.\n",
    "2024-11-05 05:25:47,878 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
    "2024-11-05 05:25:47,879 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
    "[W 2024-11-05 05:35:54,072] Trial 5 failed with parameters: {'dropout_ratio': 0.5687442299426126, 'lr': 0.0001458748799450692, 'warmup_ratio': 0.1773074887200759, 'max_norm': 34, 'with_pool2': False, 'bottleneck_mode': 'ir', 'norm_eval': False, 'bn_frozen': False} because of the following error: KeyboardInterrupt().\n",
    "Traceback (most recent call last):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fc077",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrambmix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
