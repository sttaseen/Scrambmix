{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6696d1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c5a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from mmaction.datasets import build_dataset, build_dataloader\n",
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3cec5",
   "metadata": {},
   "source": [
    "## Loading batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9df620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('./baseline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0258630",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2c341f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'RawframeDataset',\n",
       " 'ann_file': 'data/hmdb51/annotation_train.txt',\n",
       " 'data_prefix': 'data/hmdb51/rawframes',\n",
       " 'pipeline': [{'type': 'SampleFrames',\n",
       "   'clip_len': 32,\n",
       "   'frame_interval': 2,\n",
       "   'num_clips': 1},\n",
       "  {'type': 'RawFrameDecode'},\n",
       "  {'type': 'Resize', 'scale': (-1, 256)},\n",
       "  {'type': 'RandomResizedCrop'},\n",
       "  {'type': 'Resize', 'scale': (224, 224), 'keep_ratio': False},\n",
       "  {'type': 'Flip', 'flip_ratio': 0.5},\n",
       "  {'type': 'Normalize',\n",
       "   'mean': [123.675, 116.28, 103.53],\n",
       "   'std': [58.395, 57.12, 57.375],\n",
       "   'to_bgr': False},\n",
       "  {'type': 'FormatShape', 'input_format': 'NCTHW'},\n",
       "  {'type': 'Collect', 'keys': ['imgs', 'label'], 'meta_keys': []},\n",
       "  {'type': 'ToTensor', 'keys': ['imgs', 'label']}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccef55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(cfg=cfg.data.train)\n",
    "train_loader = build_dataloader(\n",
    "        train_dataset,\n",
    "        videos_per_gpu=10,\n",
    "        workers_per_gpu=4,\n",
    "        persistent_workers=False,\n",
    "        num_gpus=1,\n",
    "        dist=False)\n",
    "\n",
    "val_dataset = build_dataset(cfg=cfg.data.val)\n",
    "val_loader = build_dataloader(\n",
    "        val_dataset,\n",
    "        videos_per_gpu=1,\n",
    "        workers_per_gpu=4,\n",
    "        persistent_workers=False,\n",
    "        num_gpus=1,\n",
    "        dist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f160847",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ = iter(train_loader)\n",
    "result = next(iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85e6704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['imgs', 'label'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b839c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd79fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmaction.models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42206d96-8dbf-4c0e-adb6-5c945d82cff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Recognizer3D',\n",
       " 'backbone': {'type': 'ResNet3dCSN',\n",
       "  'pretrained2d': False,\n",
       "  'pretrained': 'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
       "  'depth': 50,\n",
       "  'with_pool2': False,\n",
       "  'bottleneck_mode': 'ir',\n",
       "  'norm_eval': True,\n",
       "  'zero_init_residual': False,\n",
       "  'bn_frozen': True},\n",
       " 'cls_head': {'type': 'I3DHead',\n",
       "  'num_classes': 52,\n",
       "  'in_channels': 2048,\n",
       "  'spatial_type': 'avg',\n",
       "  'dropout_ratio': 0.5,\n",
       "  'init_std': 0.01},\n",
       " 'train_cfg': None,\n",
       " 'test_cfg': {'average_clips': 'prob', 'max_testing_views': 10}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backbone hyperparameters\n",
    "cfg.model.backbone.with_pool2 = False\n",
    "cfg.model.backbone.pretrained = 'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth'\n",
    "cfg.model.backbone.bottleneck_mode = 'ir'\n",
    "cfg.model.backbone.norm_eval = True\n",
    "cfg.model.backbone.bn_frozen = True\n",
    "\n",
    "# Head hyperparameters\n",
    "cfg.model.cls_head.spatial_type='avg'\n",
    "cfg.model.cls_head.dropout_ratio=0.5\n",
    "\n",
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b904cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 18:06:25,682 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-11-04 18:06:25,683 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "        cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eacfdb",
   "metadata": {},
   "source": [
    "## Learning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b5656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.000125,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "# Gradient clipping configuration\n",
    "max_norm = 40\n",
    "norm_type = 2\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = MultiStepLR(optimizer, milestones=[70, 140], gamma=0.1)\n",
    "\n",
    "# Warmup settings\n",
    "warmup_epochs = 16\n",
    "warmup_start_lr = 0.000125 * 0.1  # warmup_ratio=0.1\n",
    "initial_lr = 0.000125\n",
    "\n",
    "# Training configuration\n",
    "total_epochs = 50\n",
    "eval_interval = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf8d38-2fac-42f5-973c-fc3913859d82",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c56282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msttaseen\u001b[0m (\u001b[33mcares\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sadat/Desktop/scrambmix/wandb/run-20241104_180627-3bkih1w7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cares/hmdb51-tuning/runs/3bkih1w7\" target=\"_blank\">fast-terrain-2</a></strong> to <a href=\"https://wandb.ai/cares/hmdb51-tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/50: 100%|██████████| 357/357 [02:13<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 3.9332, Training Accuracy: 0.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/50: 100%|██████████| 357/357 [02:09<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Training Loss: 3.7461, Training Accuracy: 0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/50: 100%|██████████| 357/357 [02:12<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Training Loss: 2.8245, Training Accuracy: 0.2983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/50: 100%|██████████| 357/357 [02:11<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Training Loss: 2.0675, Training Accuracy: 0.4504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/50: 100%|██████████| 357/357 [02:09<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Training Loss: 1.7406, Training Accuracy: 0.5171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 5/50: 100%|██████████| 1530/1530 [00:29<00:00, 51.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.0682, Validation Accuracy: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/50: 100%|██████████| 357/357 [02:08<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Training Loss: 1.4995, Training Accuracy: 0.5796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/50: 100%|██████████| 357/357 [01:54<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Training Loss: 1.3913, Training Accuracy: 0.6064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/50: 100%|██████████| 357/357 [01:55<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Training Loss: 1.2992, Training Accuracy: 0.6319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/50: 100%|██████████| 357/357 [01:54<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Training Loss: 1.2527, Training Accuracy: 0.6482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/50: 100%|██████████| 357/357 [02:07<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Training Loss: 1.2125, Training Accuracy: 0.6594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 10/50: 100%|██████████| 1530/1530 [00:29<00:00, 51.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8579, Validation Accuracy: 0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/50: 100%|██████████| 357/357 [02:09<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Training Loss: 1.1660, Training Accuracy: 0.6739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/50: 100%|██████████| 357/357 [02:01<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Training Loss: 1.1478, Training Accuracy: 0.6810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/50: 100%|██████████| 357/357 [01:55<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Training Loss: 1.1211, Training Accuracy: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/50: 100%|██████████| 357/357 [01:55<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Training Loss: 1.1079, Training Accuracy: 0.6871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/50: 100%|██████████| 357/357 [01:54<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Training Loss: 1.0848, Training Accuracy: 0.6994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 15/50: 100%|██████████| 1530/1530 [00:28<00:00, 54.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.0561, Validation Accuracy: 0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Training Loss: 1.0685, Training Accuracy: 0.7036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/50: 100%|██████████| 357/357 [01:54<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Training Loss: 0.9953, Training Accuracy: 0.7258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/50: 100%|██████████| 357/357 [01:54<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Training Loss: 0.9602, Training Accuracy: 0.7398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/50: 100%|██████████| 357/357 [01:54<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Training Loss: 0.9444, Training Accuracy: 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Training Loss: 0.9096, Training Accuracy: 0.7459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 20/50: 100%|██████████| 1530/1530 [00:28<00:00, 53.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9365, Validation Accuracy: 0.7366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Training Loss: 0.8699, Training Accuracy: 0.7591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/50: 100%|██████████| 357/357 [01:55<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Training Loss: 0.8611, Training Accuracy: 0.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/50: 100%|██████████| 357/357 [01:55<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Training Loss: 0.8674, Training Accuracy: 0.7594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/50: 100%|██████████| 357/357 [01:54<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Training Loss: 0.7970, Training Accuracy: 0.7782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Training Loss: 0.7466, Training Accuracy: 0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 25/50: 100%|██████████| 1530/1530 [00:28<00:00, 54.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8726, Validation Accuracy: 0.7686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/50: 100%|██████████| 357/357 [01:54<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Training Loss: 0.7478, Training Accuracy: 0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/50: 100%|██████████| 357/357 [01:54<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Training Loss: 0.7140, Training Accuracy: 0.7997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/50: 100%|██████████| 357/357 [01:54<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Training Loss: 0.6851, Training Accuracy: 0.8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Training Loss: 0.6219, Training Accuracy: 0.8241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/50: 100%|██████████| 357/357 [01:55<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Training Loss: 0.6322, Training Accuracy: 0.8258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 30/50: 100%|██████████| 1530/1530 [00:28<00:00, 53.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1147, Validation Accuracy: 0.7503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Training Loss: 0.6370, Training Accuracy: 0.8213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Training Loss: 0.6023, Training Accuracy: 0.8263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33/50: 100%|██████████| 357/357 [01:54<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Training Loss: 0.6126, Training Accuracy: 0.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Training Loss: 0.5693, Training Accuracy: 0.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Training Loss: 0.5872, Training Accuracy: 0.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 35/50: 100%|██████████| 1530/1530 [00:28<00:00, 53.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1091, Validation Accuracy: 0.7373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Training Loss: 0.5573, Training Accuracy: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37/50: 100%|██████████| 357/357 [01:54<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Training Loss: 0.5345, Training Accuracy: 0.8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38/50: 100%|██████████| 357/357 [01:55<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Training Loss: 0.4989, Training Accuracy: 0.8597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39/50:  86%|████████▋ | 308/357 [01:42<00:16,  3.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimgs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 35\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_cls\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     37\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop1_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmaction/models/recognizers/base.py:269\u001b[0m, in \u001b[0;36mBaseRecognizer.forward\u001b[0;34m(self, imgs, label, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         imgs, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblending(imgs, label)\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_test(imgs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmaction/models/recognizers/recognizer3d.py:27\u001b[0m, in \u001b[0;36mRecognizer3D.forward_train\u001b[0;34m(self, imgs, labels, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m cls_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_head(x)\n\u001b[1;32m     26\u001b[0m gt_labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 27\u001b[0m loss_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(loss_cls)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m~/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmaction/models/heads/base.py:99\u001b[0m, in \u001b[0;36mBaseHead.loss\u001b[0;34m(self, cls_score, labels, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01mand\u001b[39;00m cls_score\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m---> 99\u001b[0m     top_k_acc \u001b[38;5;241m=\u001b[39m top_k_accuracy(\u001b[43mcls_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    100\u001b[0m                                labels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    101\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopk)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopk, top_k_acc):\n\u001b[1;32m    103\u001b[0m         losses[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_acc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    104\u001b[0m             a, device\u001b[38;5;241m=\u001b[39mcls_score\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Initialize Weights and Biases\n",
    "wandb.init(project='hmdb51-tuning', entity='cares', group='baseline')  # Replace with your project and entity names\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Initialize log file\n",
    "log_file = 'training_log.txt'  # Specify the log file name\n",
    "with open(log_file, 'w') as f:  # Open the log file for writing\n",
    "    for epoch in range(total_epochs):\n",
    "        # Warmup phase\n",
    "        if epoch < warmup_epochs:\n",
    "            warmup_lr = warmup_start_lr + (initial_lr - warmup_start_lr) * (epoch / warmup_epochs)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = warmup_lr\n",
    "        else:\n",
    "            scheduler.step()  # Step the scheduler after warmup\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Training step\n",
    "        for i, data in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{total_epochs}\")):\n",
    "            inputs, labels = data['imgs'].to(device), data['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            results = model.forward(inputs, labels, return_loss=True)\n",
    "            loss = results['loss_cls']\n",
    "            train_accuracy = results['top1_acc']  \n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm, norm_type)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            correct += (results['top1_acc'] * inputs.size(0))  # Assuming top1_acc is in percentage\n",
    "            total += inputs.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        # Log training loss and accuracy\n",
    "        log_line = f\"Epoch [{epoch+1}/{total_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\\n\"\n",
    "        f.write(log_line)\n",
    "        print(log_line.strip())  # Print to console for real-time feedback\n",
    "\n",
    "        # Log training metrics to WandB\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_accuracy': train_accuracy\n",
    "        })\n",
    "\n",
    "        # Validation phase\n",
    "        if (epoch + 1) % eval_interval == 0:\n",
    "            model.eval()\n",
    "            val_running_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_data in tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}/{total_epochs}\"):\n",
    "                    val_inputs, val_labels = val_data['imgs'].to(device), val_data['label'].to(device)\n",
    "                    \n",
    "                    val_results = model.forward(val_inputs, val_labels, return_loss=True)\n",
    "                    val_loss = val_results['loss_cls']\n",
    "                    val_accuracy = val_results['top1_acc']\n",
    "\n",
    "                    val_running_loss += val_loss.item()\n",
    "                    val_correct += (val_accuracy * val_inputs.size(0))\n",
    "                    val_total += val_inputs.size(0)\n",
    "\n",
    "            val_loss = val_running_loss / len(val_loader)\n",
    "            val_accuracy = val_correct / val_total\n",
    "\n",
    "            # Log validation loss and accuracy\n",
    "            val_log_line = f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\\n\"\n",
    "            f.write(val_log_line)\n",
    "            print(val_log_line.strip())  # Print to console for real-time feedback\n",
    "\n",
    "            # Log validation metrics to WandB\n",
    "            wandb.log({\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_accuracy\n",
    "            })\n",
    "\n",
    "print(\"Training complete.\")\n",
    "wandb.finish()  # Finish the WandB run\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrambmix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
