{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6696d1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c5a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/home/sadat/miniconda3/envs/scrambmix/lib/python3.8/site-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.17.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from mmaction.datasets import build_dataset, build_dataloader\n",
    "from mmaction.models import build_model\n",
    "from mmcv import Config\n",
    "from mmaction.datasets import MixupBlending\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7213c530-c45b-4a67-8860-2687d47eace4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def precision_score(y_true, y_pred):\n",
    "    \"\"\"Calculates precision score.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Precision score.\n",
    "    \"\"\"\n",
    "\n",
    "    tp = sum(y_true[i] == y_pred[i] for i in range(len(y_true)) if y_pred[i] == 1)\n",
    "    fp = sum(y_true[i] != y_pred[i] for i in range(len(y_true)) if y_pred[i] == 1)\n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "    return precision\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    \"\"\"Calculates recall score.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Recall score.\n",
    "    \"\"\"\n",
    "\n",
    "    tp = sum(y_true[i] == y_pred[i] for i in range(len(y_true)) if y_pred[i] == 1)\n",
    "    fn = sum(y_true[i] == 1 and y_pred[i] != 1 for i in range(len(y_true)))\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else 0\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Calculates F1 score.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        F1 score.\n",
    "    \"\"\"\n",
    "\n",
    "    p = precision_score(y_true, y_pred)\n",
    "    r = recall_score(y_true, y_pred)\n",
    "    return 2 * p * r / (p + r) if p + r != 0 else 0\n",
    "\n",
    "def weighted_f1_score(y_true, y_pred):\n",
    "    \"\"\"Calculates the weighted F1 score, assuming equal class weights.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Weighted F1 score.\n",
    "    \"\"\"\n",
    "\n",
    "    num_classes = len(set(y_true))\n",
    "    f1_scores = []\n",
    "    for i in range(num_classes):\n",
    "        class_mask = [1 if y == i else 0 for y in y_true]\n",
    "        class_f1 = f1_score(class_mask, [1 if y == i else 0 for y in y_pred])\n",
    "        f1_scores.append(class_f1)\n",
    "    return sum(f1_scores) / num_classes\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Calculates the accuracy score.\n",
    "    \n",
    "    Args:\n",
    "    y_true: True labels.\n",
    "    y_pred: Predicted labels.\n",
    "    \n",
    "    Returns:\n",
    "    Accuracy score.\n",
    "    \"\"\"\n",
    "    \n",
    "    correct_predictions = sum(np.array(y_true) == np.array(y_pred))\n",
    "    total_predictions = len(y_true)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3cec5",
   "metadata": {},
   "source": [
    "## Loading batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9df620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('./mixup.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0258630",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2c341f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'RawframeDataset',\n",
       " 'ann_file': 'data/hmdb51/annotation_train.txt',\n",
       " 'data_prefix': 'data/hmdb51/rawframes',\n",
       " 'pipeline': [{'type': 'SampleFrames',\n",
       "   'clip_len': 32,\n",
       "   'frame_interval': 2,\n",
       "   'num_clips': 1},\n",
       "  {'type': 'RawFrameDecode'},\n",
       "  {'type': 'Resize', 'scale': (-1, 256)},\n",
       "  {'type': 'RandomResizedCrop'},\n",
       "  {'type': 'Resize', 'scale': (224, 224), 'keep_ratio': False},\n",
       "  {'type': 'Flip', 'flip_ratio': 0.5},\n",
       "  {'type': 'Normalize',\n",
       "   'mean': [123.675, 116.28, 103.53],\n",
       "   'std': [58.395, 57.12, 57.375],\n",
       "   'to_bgr': False},\n",
       "  {'type': 'FormatShape', 'input_format': 'NCTHW'},\n",
       "  {'type': 'Collect', 'keys': ['imgs', 'label'], 'meta_keys': []},\n",
       "  {'type': 'ToTensor', 'keys': ['imgs', 'label']}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccef55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(cfg=cfg.data.train)\n",
    "train_loader = build_dataloader(\n",
    "        train_dataset,\n",
    "        videos_per_gpu=8,\n",
    "        workers_per_gpu=4,\n",
    "        persistent_workers=False,\n",
    "        num_gpus=1,\n",
    "        dist=False)\n",
    "\n",
    "val_dataset = build_dataset(cfg=cfg.data.val)\n",
    "val_loader = build_dataloader(\n",
    "        val_dataset,\n",
    "        videos_per_gpu=1,\n",
    "        workers_per_gpu=4,\n",
    "        persistent_workers=False,\n",
    "        num_gpus=1,\n",
    "        dist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eacfdb",
   "metadata": {},
   "source": [
    "## Use MMAction2's Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dbfd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters from previous study\n",
    "best_params = {\n",
    "    'dropout_ratio': 0.6795542149013333,\n",
    "    'lr': 7.886714129990479e-06,\n",
    "    'max_norm': 41,\n",
    "    'with_pool2': True,\n",
    "    'bottleneck_mode': 'ir',\n",
    "    'norm_eval': False,\n",
    "    'bn_frozen': False,\n",
    "    'alpha': 1.0 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b5656d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 13:07:28,317 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2024-12-12 13:07:28,317 - mmaction - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Train Loss: 3.9237\n",
      "Epoch 1, Validation Loss: 3.7029, Accuracy: 0.2614, Average F1 Score: 0.2081\n",
      "Epoch 1, New best validation loss: 3.7029\n",
      "Epoch [2/60], Train Loss: 3.7242\n",
      "Epoch 2, Validation Loss: 3.1874, Accuracy: 0.3948, Average F1 Score: 0.3246\n",
      "Epoch 2, New best validation loss: 3.1874\n",
      "Epoch [3/60], Train Loss: 3.5424\n",
      "Epoch 3, Validation Loss: 2.8146, Accuracy: 0.4830, Average F1 Score: 0.4098\n",
      "Epoch 3, New best validation loss: 2.8146\n",
      "Epoch [4/60], Train Loss: 3.3846\n",
      "Epoch 4, Validation Loss: 2.5024, Accuracy: 0.5000, Average F1 Score: 0.4237\n",
      "Epoch 4, New best validation loss: 2.5024\n",
      "Epoch [5/60], Train Loss: 3.2544\n",
      "Epoch 5, Validation Loss: 2.2778, Accuracy: 0.5425, Average F1 Score: 0.4722\n",
      "Epoch 5, New best validation loss: 2.2778\n",
      "Epoch [6/60], Train Loss: 3.1196\n",
      "Epoch 6, Validation Loss: 2.0664, Accuracy: 0.5719, Average F1 Score: 0.5123\n",
      "Epoch 6, New best validation loss: 2.0664\n",
      "Epoch [7/60], Train Loss: 2.9899\n",
      "Epoch 7, Validation Loss: 1.8395, Accuracy: 0.6000, Average F1 Score: 0.5432\n",
      "Epoch 7, New best validation loss: 1.8395\n",
      "Epoch [8/60], Train Loss: 2.9047\n",
      "Epoch 8, Validation Loss: 1.6970, Accuracy: 0.6281, Average F1 Score: 0.5712\n",
      "Epoch 8, New best validation loss: 1.6970\n",
      "Epoch [9/60], Train Loss: 2.7994\n",
      "Epoch 9, Validation Loss: 1.5841, Accuracy: 0.6549, Average F1 Score: 0.6030\n",
      "Epoch 9, New best validation loss: 1.5841\n",
      "Epoch [10/60], Train Loss: 2.7014\n",
      "Epoch 10, Validation Loss: 1.4664, Accuracy: 0.6732, Average F1 Score: 0.6288\n",
      "Epoch 10, New best validation loss: 1.4664\n",
      "Epoch [11/60], Train Loss: 2.6367\n",
      "Epoch 11, Validation Loss: 1.3447, Accuracy: 0.6830, Average F1 Score: 0.6384\n",
      "Epoch 11, New best validation loss: 1.3447\n",
      "Epoch [12/60], Train Loss: 2.5317\n",
      "Epoch 12, Validation Loss: 1.2598, Accuracy: 0.7007, Average F1 Score: 0.6635\n",
      "Epoch 12, New best validation loss: 1.2598\n",
      "Epoch [13/60], Train Loss: 2.4682\n",
      "Epoch 13, Validation Loss: 1.2399, Accuracy: 0.7124, Average F1 Score: 0.6844\n",
      "Epoch 13, New best validation loss: 1.2399\n",
      "Epoch [14/60], Train Loss: 2.4142\n",
      "Epoch 14, Validation Loss: 1.1676, Accuracy: 0.7222, Average F1 Score: 0.6906\n",
      "Epoch 14, New best validation loss: 1.1676\n",
      "Epoch [15/60], Train Loss: 2.3636\n",
      "Epoch 15, Validation Loss: 1.1014, Accuracy: 0.7281, Average F1 Score: 0.7000\n",
      "Epoch 15, New best validation loss: 1.1014\n",
      "Epoch [16/60], Train Loss: 2.3347\n",
      "Epoch 16, Validation Loss: 1.1009, Accuracy: 0.7359, Average F1 Score: 0.7096\n",
      "Epoch 16, New best validation loss: 1.1009\n",
      "Epoch [17/60], Train Loss: 2.3071\n",
      "Epoch 17, Validation Loss: 1.0559, Accuracy: 0.7451, Average F1 Score: 0.7249\n",
      "Epoch 17, New best validation loss: 1.0559\n",
      "Epoch [18/60], Train Loss: 2.3346\n",
      "Epoch 18, Validation Loss: 1.0102, Accuracy: 0.7523, Average F1 Score: 0.7291\n",
      "Epoch 18, New best validation loss: 1.0102\n",
      "Epoch [19/60], Train Loss: 2.1582\n",
      "Epoch 19, Validation Loss: 0.9905, Accuracy: 0.7464, Average F1 Score: 0.7253\n",
      "Epoch 19, New best validation loss: 0.9905\n",
      "Epoch [20/60], Train Loss: 2.1892\n",
      "Epoch 20, Validation Loss: 1.0023, Accuracy: 0.7556, Average F1 Score: 0.7362\n",
      "Epoch [21/60], Train Loss: 2.1503\n",
      "Epoch 21, Validation Loss: 1.0042, Accuracy: 0.7516, Average F1 Score: 0.7287\n",
      "Epoch [22/60], Train Loss: 2.1241\n",
      "Epoch 22, Validation Loss: 0.9416, Accuracy: 0.7536, Average F1 Score: 0.7325\n",
      "Epoch 22, New best validation loss: 0.9416\n",
      "Epoch [23/60], Train Loss: 2.0999\n",
      "Epoch 23, Validation Loss: 0.9436, Accuracy: 0.7601, Average F1 Score: 0.7389\n",
      "Epoch [24/60], Train Loss: 2.0588\n",
      "Epoch 24, Validation Loss: 0.8995, Accuracy: 0.7614, Average F1 Score: 0.7439\n",
      "Epoch 24, New best validation loss: 0.8995\n",
      "Epoch [25/60], Train Loss: 2.0385\n",
      "Epoch 25, Validation Loss: 0.9391, Accuracy: 0.7562, Average F1 Score: 0.7373\n",
      "Epoch [26/60], Train Loss: 2.0115\n",
      "Epoch 26, Validation Loss: 0.9150, Accuracy: 0.7549, Average F1 Score: 0.7405\n",
      "Epoch [27/60], Train Loss: 1.9940\n",
      "Epoch 27, Validation Loss: 0.8987, Accuracy: 0.7680, Average F1 Score: 0.7510\n",
      "Epoch 27, New best validation loss: 0.8987\n",
      "Epoch [28/60], Train Loss: 1.9921\n",
      "Epoch 28, Validation Loss: 0.8891, Accuracy: 0.7601, Average F1 Score: 0.7465\n",
      "Epoch 28, New best validation loss: 0.8891\n",
      "Epoch [29/60], Train Loss: 1.9522\n",
      "Epoch 29, Validation Loss: 0.8956, Accuracy: 0.7582, Average F1 Score: 0.7445\n",
      "Epoch [30/60], Train Loss: 1.9036\n",
      "Epoch 30, Validation Loss: 0.8929, Accuracy: 0.7556, Average F1 Score: 0.7402\n",
      "Epoch [31/60], Train Loss: 1.9565\n",
      "Epoch 31, Validation Loss: 0.8834, Accuracy: 0.7608, Average F1 Score: 0.7487\n",
      "Epoch 31, New best validation loss: 0.8834\n",
      "Epoch [32/60], Train Loss: 1.8776\n",
      "Epoch 32, Validation Loss: 0.9059, Accuracy: 0.7529, Average F1 Score: 0.7364\n",
      "Epoch [33/60], Train Loss: 1.8487\n",
      "Epoch 33, Validation Loss: 0.8856, Accuracy: 0.7595, Average F1 Score: 0.7469\n",
      "Epoch [34/60], Train Loss: 1.9012\n",
      "Epoch 34, Validation Loss: 0.8773, Accuracy: 0.7667, Average F1 Score: 0.7548\n",
      "Epoch 34, New best validation loss: 0.8773\n",
      "Epoch [35/60], Train Loss: 1.8963\n",
      "Epoch 35, Validation Loss: 0.8976, Accuracy: 0.7588, Average F1 Score: 0.7471\n",
      "Epoch [36/60], Train Loss: 1.8833\n",
      "Epoch 36, Validation Loss: 0.9304, Accuracy: 0.7510, Average F1 Score: 0.7391\n",
      "Epoch [37/60], Train Loss: 1.8349\n",
      "Epoch 37, Validation Loss: 0.9004, Accuracy: 0.7562, Average F1 Score: 0.7433\n",
      "Epoch [38/60], Train Loss: 1.8287\n",
      "Epoch 38, Validation Loss: 0.9017, Accuracy: 0.7556, Average F1 Score: 0.7423\n",
      "Epoch [39/60], Train Loss: 1.8104\n",
      "Epoch 39, Validation Loss: 0.8873, Accuracy: 0.7562, Average F1 Score: 0.7431\n",
      "Early stopping at epoch 39 due to no improvement in validation loss.\n",
      "Training complete. Best validation loss: 0.8773. Log saved to training_log.csv.\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True  # Ensures deterministic behavior (might slow down training)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='training_adam_mixup_min_loss.log', \n",
    "                    filemode='w', \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    level=logging.INFO)\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set hyperparameters directly\n",
    "dropout_ratio = best_params['dropout_ratio']\n",
    "lr = best_params['lr']\n",
    "max_norm = best_params['max_norm']\n",
    "alpha = best_params['alpha']\n",
    "\n",
    "# Backbone parameters\n",
    "cfg.model.backbone.with_pool2 = best_params['with_pool2']\n",
    "cfg.model.backbone.bottleneck_mode = best_params['bottleneck_mode']\n",
    "cfg.model.backbone.norm_eval = best_params['norm_eval']\n",
    "cfg.model.backbone.bn_frozen = best_params['bn_frozen']\n",
    "\n",
    "# Fixed pretrained URL\n",
    "cfg.model.backbone.pretrained = 'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth'\n",
    "\n",
    "# Adjust config parameters\n",
    "cfg.model.cls_head.dropout_ratio = dropout_ratio\n",
    "\n",
    "# Initialize model, criterion, optimizer, scheduler\n",
    "model = build_model(cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg')).to(device)\n",
    "# model.cls_head.loss_cls = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    weight_decay=0.00001\n",
    ")\n",
    "\n",
    "# Early stopping parameters\n",
    "total_epochs = 60\n",
    "eval_interval = 1\n",
    "patience = 5\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_without_improvement = 5\n",
    "\n",
    "# Mixup Blending instance\n",
    "mixup = MixupBlending(num_classes=cfg.model.cls_head.num_classes, alpha=alpha)\n",
    "\n",
    "\n",
    "# Initialize lists to store losses and accuracy\n",
    "training_log = []\n",
    "\n",
    "\n",
    "# Validation loop with accuracy and F1 score calculation\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for _, data in enumerate(train_loader):\n",
    "        inputs, labels = data['imgs'].to(device), data['label'].to(device)\n",
    "\n",
    "        # Convert labels to one-hot encoding\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=cfg.model.cls_head.num_classes).float()\n",
    "\n",
    "        # Apply Mixup\n",
    "        mixed_inputs, mixed_labels = mixup.do_blending(inputs, labels_one_hot)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mixed_inputs, mixed_labels, return_loss=True)\n",
    "        loss = outputs['loss_cls']\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{total_epochs}], Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation loop (every `eval_interval` epochs)\n",
    "    if (epoch + 1) % eval_interval == 0:\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = val_data['imgs'].to(device), val_data['label'].to(device)\n",
    "\n",
    "                val_results = model(val_inputs, return_loss=False)\n",
    "                val_loss = model(val_inputs, val_labels, return_loss=True)['loss_cls']\n",
    "\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                # Collect predictions and true labels\n",
    "                predictions = np.argmax(val_results, axis=1)\n",
    "                true_labels = val_labels.cpu().numpy()\n",
    "\n",
    "                all_preds.extend(predictions)\n",
    "                all_labels.extend(true_labels)\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        avg_f1 = weighted_f1_score(all_labels, all_preds)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}, Average F1 Score: {avg_f1:.4f}')\n",
    "\n",
    "        # Check if validation loss improved\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_without_improvement = 0  # Reset counter\n",
    "            print(f'Epoch {epoch + 1}, New best validation loss: {avg_val_loss:.4f}')\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        # Early stopping check\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping at epoch {epoch + 1} due to no improvement in validation loss.')\n",
    "            break\n",
    "\n",
    "        # Log results for this epoch\n",
    "        training_log.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'accuracy': accuracy,\n",
    "            'avg_f1': avg_f1,\n",
    "            'type': 'baseline'\n",
    "        })\n",
    "\n",
    "# Convert the log to a DataFrame\n",
    "df = pd.DataFrame(training_log)\n",
    "\n",
    "# Write the log to a CSV file\n",
    "csv_file = 'training_log.csv'\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"Training complete. Best validation loss: {best_val_loss:.4f}. Log saved to {csv_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrambmix",
   "language": "python",
   "name": "scrambmix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
